{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "031d435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RSPRASAD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein==0.12.0 in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (0.12.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: setuptools in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (from python-Levenshtein==0.12.0) (65.6.3)\n",
      "Requirement already satisfied: jarowinkler in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.5.2 in c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages (from jarowinkler) (3.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rsprasad\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk.data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import random\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "!pip install geopy\n",
    "!pip install python-Levenshtein==0.12.0\n",
    "!pip install jarowinkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "804b81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Input file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bd472fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[:,['Account Name','Billing Country','Billing State/Province','Billing City','Billing Street','Billing Zip/Postal Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "38cba68f",
   "metadata": {},
  
   "source": [
    "\n",
    "df2 = df.loc[:,['Account Name','Billing Country','Billing State/Province','Billing City','Billing Street',\\\n",
    "                'Billing Zip/Postal Code']]\n",
    "df_count= pd.DataFrame()\n",
    "\n",
    "df_count['Entity'] = ''\n",
    "df_count['Percent'] = ''\n",
    "df_count['Number'] = ''\n",
    "\n",
    "num_records = len(df2)\n",
    "\n",
    "df2 = df2.iloc[0:num_records,:]\n",
    "df2 = df2.astype(str).apply(lambda x:x.str.lower())\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "count = 0\n",
    "flag = 0\n",
    "stop_words = []\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "df2['Account ID'] = df['Account ID']\n",
    "def remove_stop_words(text):\n",
    "    global df_count\n",
    "    global flag\n",
    "    global stop_words\n",
    "  \n",
    "    global count\n",
    "    text2 = ''\n",
    "    if(len(df_count)==0):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "    else:\n",
    "  \n",
    "        if(flag ==0):\n",
    "            for count in range(len(df_count)):\n",
    "                if(df_count.loc[count, 'Number']<100):\n",
    "                    flag = 1\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        stop_words = set(df_count.loc[0:count-1,'Entity'])\n",
    "    \n",
    "    \n",
    "        \n",
    "    word_tokens = word_tokenize(text)\n",
    " \n",
    "    filtered_sentence = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "            text2 += w + ' '\n",
    "\n",
    "    text2 = text2.strip()\n",
    "    return text2\n",
    "\n",
    "df3 = df2.copy(deep = True)\n",
    "df2['Account Name'] = df2['Account Name'].apply(remove_stop_words)\n",
    "df2['Billing Street'] = df2['Billing Street'].apply(remove_stop_words)\n",
    "df2 = df2.astype(str).replace(\"[\\'\\\".,()*+&\\/\\-\\\\\\+\\!\\%:;?]\",\"\")\n",
    "#df2=df3\n",
    "\n",
    "print(\"Stop words (1st time) are...\", stop_words)\n",
    "df_count['Entity'] = df2['Account Name'].str.split(expand=True).stack().value_counts().index\n",
    "df_count['Number'] = list(df2['Account Name'].str.split(expand=True).stack().value_counts().values)\n",
    "sum1 = df2['Account Name'].str.split(expand=True).stack().value_counts().sum()\n",
    "df_count['Percent'] = list((df2['Account Name'].str.split(expand=True).stack().value_counts()/sum1).values)\n",
    "\n",
    "\n",
    "df3['Account Name'] = df3['Account Name'].apply(remove_stop_words)\n",
    "df3['Billing Street'] = df3['Billing Street'].apply(remove_stop_words)\n",
    "df3 = df3.astype(str).replace(\"[\\'\\\".,()*+&\\/\\-\\\\\\+\\!\\%:;?]\",\"\")\n",
    "print(\"Stop words (2nd time) are...\", stop_words)\n",
    "#df2=df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a66e7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = df.loc[:, ['Account ID', 'Account Name']]\n",
    "df_lookup.head()\n",
    "df2 = pd.merge(df2,df_lookup, on = 'Account ID', how = 'left')\n",
    "df2.rename(columns = {'Account Name_x':'Account Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2c383420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
   
    }
   ],
   "source": [
    "stop_words2 = []\n",
    "for item in stop_words:\n",
    "    if len(item)>1:\n",
    "        stop_words2.append(item)\n",
    "\n",
    "stop_words2 = set(stop_words)\n",
    "print(stop_words2)\n",
    "stop_words = stop_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51846dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     
  
      

    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in account number.. 16527\n",
      "I am in account number.. 16528\n",
      "I am in account number.. 16529\n",
      "I am in account number.. 16530\n",
      "I am in account number.. 16531\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein\n",
    "\n",
    "from jarowinkler import *\n",
    "\n",
    "df3 = df2\n",
    "len_df3 = len(df3)\n",
    "score = 0\n",
    "score2= 0\n",
    "index = 0\n",
    "df3['Address_All'] = ''\n",
    "\n",
    "for j in range(0, len(df3)):\n",
    "    df3.loc[j,'Address_All'] = str(df3.loc[j,'Billing Country']) + ' '+ str(df3.loc[j,'Billing State/Province'])\\\n",
    "+ ' '+  str(df3.loc[j,'Billing City']) + ' '+str(df3.loc[j,'Billing Street'])\\\n",
    "+ ' '+ str(df3.loc[j,'Billing Zip/Postal Code'])\n",
    "\n",
    "df_accounts = pd.DataFrame()\n",
    "df_accounts['Id1'] = ''\n",
    "df_accounts['Name1'] = ''\n",
    "df_accounts['Id2'] = ''\n",
    "df_accounts['Name2'] = ''\n",
    "df_accounts['Original Name1'] = ''\n",
    "df_accounts['Original Name2'] = ''\n",
    "'''df_accounts2['Name1'] = ''\n",
    "df_accounts2['Name2'] = '''''\n",
    "\n",
    "\n",
    "for i in range(0, len_df3):\n",
    "    print(\"I am in account number..\", i)\n",
    "    for j in range( i+1, len_df3):\n",
    "        '''df_accounts2.loc[index, 'Name1'] = df3.loc[i,'Account Name']\n",
    "        df_accounts2.loc[index, 'Name2'] = df3.loc[j,'Account Name']'''\n",
    "        temp1 = df3.loc[i, 'Account Name']\n",
    "        temp2 = df3.loc[j,'Account Name']\n",
    "        for item in stop_words:\n",
    "            if(any(item == word for word in temp1.split()) and any(item == word for word in temp2.split())):\n",
    "                temp1 = temp1.replace(item, ' ').strip()\n",
    "                temp2 = temp2.replace(item, ' ').strip()\n",
    "                #print(f\"temp1 is {temp1} and temp2 is {temp2} and item is {item}\")\n",
    "                \n",
    "        score  =  jaro_similarity(temp1, temp2)\n",
    "        if(score > 0.91 and df3.loc[i, 'Account Name'] !='' and df3.loc[j,'Account Name']!= ''):\n",
    "            #print(f\"temp1 is {temp1} and temp2 is {temp2}\")\n",
    "            #print(f\"original accounts are {df3.loc[i, 'Account Name_y']} and {df3.loc[j, 'Account Name_y']}\")\n",
    "            df_accounts.loc[index, 'Id1'] = df3.loc[i, 'Account ID']\n",
    "            df_accounts.loc[index, 'Id2'] = df3.loc[j, 'Account ID']\n",
    "            df_accounts.loc[index, 'Name1'] = temp1\n",
    "            df_accounts.loc[index, 'Name2'] = temp2\n",
    "            df_accounts.loc[index, 'Original Name1'] = df3.loc[i, 'Account Name_y']\n",
    "            df_accounts.loc[index, 'Original Name2'] = df3.loc[j, 'Account Name_y']\n",
    "            df_accounts.loc[index, 'Address1'] = df3.loc[i, 'Address_All']\n",
    "            df_accounts.loc[index, 'Address2'] = df3.loc[j, 'Address_All']\n",
    "\n",
    "            df_accounts.loc[index, 'Similarity_Name'] = score\n",
    "            score2  =  jaro_similarity(df3.loc[i, 'Address_All'], df3.loc[j,'Address_All'])\n",
    "            df_accounts.loc[index, 'Similarity_Address'] = score2\n",
    "        index +=1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
